# AWS WordPress Benchmark: Tuning e AnÃ¡lise de Escalabilidade

Este repositÃ³rio contÃ©m os artefatos, scripts e resultados do projeto de Benchmarking de um cluster WordPress na AWS. O objetivo foi maximizar a capacidade de atendimento (usuÃ¡rios simultÃ¢neos) respeitando um SLA de latÃªncia (< 10s) e um orÃ§amento estrito de infraestrutura (< US$ 0.50/h).

## ðŸ‘¨â€ðŸ’» IdentificaÃ§Ã£o
* **Nome:** Rener Menezes
* **MatrÃ­cula:** 2519170
* **Curso:** Mestrado em InformÃ¡tica Aplicada - UNIFOR
* **Disciplina:** ComputaÃ§Ã£o em Nuvem

---

## ðŸš€ 1. EstratÃ©gia Adotada

Para atingir os objetivos de performance, adotamos uma estratÃ©gia hÃ­brida de **Escalabilidade Horizontal (Scale-out)** combinada com **Tuning Agressivo de Software**.

* **Por que Scale-out?**
    Utilizamos **5 instÃ¢ncias `c5.large`** para a camada de aplicaÃ§Ã£o. A escolha da famÃ­lia `c5` (Compute Optimized) foi fundamental para lidar com o processamento PHP do WordPress, enquanto a distribuiÃ§Ã£o em 5 nÃ³s permitiu paralelizar o atendimento das requisiÃ§Ãµes via Load Balancer.

* **Por que Tuning de Software?**
    Apenas escalar as mÃ¡quinas nÃ£o foi suficiente. Nos testes iniciais, o sistema falhou com gargalos de I/O de disco e conexÃµes de banco de dados, mesmo com CPU sobrando. O tuning foi necessÃ¡rio para remover travas lÃ³gicas no Apache e no MariaDB.

---

## ðŸ—ï¸ 2. Arquitetura Final

A infraestrutura final que sustentou a carga mÃ¡xima foi composta por:

* **AplicaÃ§Ã£o (Auto Scaling Group):** 5x instÃ¢ncias `c5.large` (2 vCPU, 4GB RAM).
* **Banco de Dados:** 1x instÃ¢ncia `c5.large` (2 vCPU, 4GB RAM).
* **Sistema Operacional:** Amazon Linux 2.
* **Servidor Web:** Apache 2.4 com PHP 7.2.
* **Banco de Dados:** MariaDB 10.2.

### ðŸ”§ Detalhes do Tuning

Para atingir a performance final, aplicamos as seguintes otimizaÃ§Ãµes crÃ­ticas via scripts de `user_data`:

#### A. Camada de Banco de Dados (MariaDB)
O gargalo principal era o I/O do disco EBS (IOPS).
* `innodb_flush_log_at_trx_commit = 2`: **Crucial.** Mudamos a escrita em disco de "tempo real" para "cada 1 segundo". Isso aumentou a velocidade de escrita em ~10x.
* `max_connections = 2000`: Aumentado de 151 (padrÃ£o) para evitar erros de conexÃ£o recusada com 5 servidores web.
* `innodb_buffer_pool_size = 2G`: Ajustado para usar 50% da RAM dedicada ao cache.
* `skip-name-resolve`: Desativado o DNS reverso para diminuir latÃªncia de rede.

#### B. Camada de AplicaÃ§Ã£o (Apache/PHP)
O gargalo era o gerenciamento de memÃ³ria e a latÃªncia com o Load Balancer.
* `ServerLimit` / `MaxRequestWorkers = 150`: Calculado para ocupar a RAM disponÃ­vel (4GB) sem causar *swap*.
* `KeepAliveTimeout = 5`: Aumentado para manter conexÃµes persistentes com o Load Balancer, reduzindo o *overhead* de *TCP Handshake*.
* **Logs Desativados:** `CustomLog` comentado para evitar que a escrita de logs de acesso saturasse o I/O do disco da aplicaÃ§Ã£o.

---

## ðŸ“Š 3. Resultados Obtidos

Realizamos uma bateria de testes progressivos ("Step-up Test") para determinar o Ponto de Ruptura do sistema.

### Capacidade MÃ¡xima Sustentada: **150 UsuÃ¡rios**

| MÃ©trica | Resultado | Limite/SLA | Status |
| :--- | :--- | :--- | :--- |
| **RPS MÃ¡ximo** | ~25.6 req/s | N/A | âœ… EstÃ¡vel |
| **LatÃªncia P95** | **6.800 ms** | < 10.000 ms | âœ… Aprovado |
| **Taxa de Erro** | **0.00%** | < 1% | âœ… Aprovado |

### HistÃ³rico de Testes (DeterminaÃ§Ã£o do Limite)

| CenÃ¡rio (UsuÃ¡rios) | LatÃªncia P95 | Taxa de Erro | ConclusÃ£o |
| :--- | :--- | :--- | :--- |
| **100** | 6.1s | 0% | Sistema operando com folga. |
| **150** | **6.8s** | **0%** | **Ponto Ã“timo (Sweet Spot).** |
| **180** | 15.0s | 0% | DegradaÃ§Ã£o de performance (ViolaÃ§Ã£o de SLA). |
| **200** | 17.0s | 0% | SaturaÃ§Ã£o de I/O e fila de processamento. |
| **300** | 26.0s | 0% | Colapso da latÃªncia. |

### EvidÃªncias GrÃ¡ficas
> *Os grÃ¡ficos abaixo foram gerados a partir dos dados brutos do teste de 150 usuÃ¡rios.*

**1. VazÃ£o (RPS) vs UsuÃ¡rios SimultÃ¢neos**
![GrÃ¡fico RPS](graficos/grafico_rps.png)

**2. LatÃªncia (Tempo de Resposta) vs Tempo**
![GrÃ¡fico LatÃªncia](graficos/grafico_latencia.png)

---

## ðŸ’° 4. AnÃ¡lise de Custos

O orÃ§amento estipulado para a **Camada de AplicaÃ§Ã£o** era de US$ 0.50/hora.

| Recurso | Tipo | PreÃ§o UnitÃ¡rio (us-east-1) | Qtd | Custo Total/Hora |
| :--- | :--- | :--- | :--- | :--- |
| EC2 App Server | c5.large | US$ 0.085 | 5 | **US$ 0.425** |

**ConclusÃ£o:** O custo final de **US$ 0.425/h** ficou **abaixo** do limite de US$ 0.50/h, provando a eficiÃªncia econÃ´mica da arquitetura escolhida.

---

## ðŸ“‚ 5. Estrutura do RepositÃ³rio

```text
.
â”œâ”€â”€ readme.md                # Este relatÃ³rio
â”œâ”€â”€ relatorio_tecnico.pdf    # VersÃ£o PDF oficial para entrega
â”œâ”€â”€ arena/
â”‚   â”œâ”€â”€ deploy_app.sh           # Script de deploy da infraestrutura
â”‚   â”œâ”€â”€ deploy_generator.sh     # Script de deploy do gerador de carga
â”‚   â”œâ”€â”€ lab-arena.yaml          # ConfiguraÃ§Ã£o do ambiente de testes
â”‚   â”œâ”€â”€ run_remote_test.sh      # Script de execuÃ§Ã£o do Locust
â”‚   â”œâ”€â”€ teardown.sh             # Script de destruiÃ§Ã£o da infraestrutura
â”‚   â”œâ”€â”€ user_data_template.sh   # Script de provisionamento (template)
â”‚   â”œâ”€â”€ user_data_final.sh      # Script de provisionamento final (contÃ©m o tuning)
â”‚   â””â”€â”€ user_data_locust.sh     # Script de provisionamento do Locust
â”œâ”€â”€ src/
â”‚   â””â”€â”€ chart.py                # Script Python para geraÃ§Ã£o de grÃ¡ficos
â”œâ”€â”€ resultados/
â”‚   â”œâ”€â”€ resultados_100users_2m_20251213_173448/
â”‚   â”œâ”€â”€ resultados_100users_2m_20251215_173338/
â”‚   â”œâ”€â”€ resultados_150users_2m_20251215_174322/  # Logs brutos (CSV) do cenÃ¡rio vencedor
â”‚   â”œâ”€â”€ resultados_180users_2m_20251215_175104/
â”‚   â”œâ”€â”€ resultados_200users_2m_20251215_174658/
â”‚   â””â”€â”€ resultados_300users_2m_20251215_081934/
â””â”€â”€ graficos/
    â”œâ”€â”€ grafico_rps.png
    â””â”€â”€ grafico_latencia.png